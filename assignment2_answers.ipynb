{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a972d6d",
   "metadata": {},
   "source": [
    "### QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab28d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION\n",
      "----------------------------------------\n",
      "Coefficients:\n",
      "          Coefficient\n",
      "size       143.218532\n",
      "bedroom -13512.564426\n",
      "Intercept: 84763.62\n",
      "\n",
      "Metrics:\n",
      "MAE:  72334.75\n",
      "MSE:  8610424544.78\n",
      "RMSE: 92792.37\n",
      "MAPE: 0.1746 (17.46%)\n",
      "\n",
      "\n",
      "SGD REGRESSOR\n",
      "----------------------------------------\n",
      "Coefficients (scaled features):\n",
      "           Coefficient\n",
      "size     106535.910237\n",
      "bedroom  -10274.951289\n",
      "Intercept: 323155.83\n",
      "\n",
      "Metrics:\n",
      "MAE:  72124.61\n",
      "MSE:  8595003325.39\n",
      "RMSE: 92709.24\n",
      "MAPE: 0.1740 (17.40%)\n",
      "\n",
      "\n",
      "MODEL COMPARISON\n",
      "----------------------------------------\n",
      "  Metric  LinearRegression  SGDRegressor\n",
      "0    MAE      7.233475e+04  7.212461e+04\n",
      "1    MSE      8.610425e+09  8.595003e+09\n",
      "2   RMSE      9.279237e+04  9.270924e+04\n",
      "3   MAPE      1.746000e-01  1.740000e-01\n",
      "\n",
      "\n",
      "METRICS TRADE-OFFS\n",
      "----------------------------------------\n",
      "MAE  - Average absolute error, robust to outliers.\n",
      "MSE  - Penalizes large errors more due to squaring.\n",
      "RMSE - Same units as target; balances MAE and MSE.\n",
      "MAPE - Scale-independent; expresses error in %.\n",
      "\n",
      "Note: RMSE is often preferred because it:\n",
      "- Uses the same unit as the target variable\n",
      "- Penalizes larger errors more than MAE\n",
      "- Is more interpretable than MSE in most cases\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# ===============================\n",
    "# Step 1: Load and Prepare Data\n",
    "# ===============================\n",
    "\n",
    "# Load housing dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\rtape\\Downloads\\Seneca\\CVI620NSB_Summer2025\\codes\\Assignment2\\Q1\\house_price.csv\")\n",
    "\n",
    "# Select features (size, bedroom) and target (price)\n",
    "X = df[['size', 'bedroom']]\n",
    "y = df['price']\n",
    "\n",
    "# Split into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===============================\n",
    "# Step 2: Linear Regression Model\n",
    "# ===============================\n",
    "\n",
    "print(\"LINEAR REGRESSION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Initialize and train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Display learned coefficients\n",
    "coeff_df = pd.DataFrame(lr_model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(\"Coefficients:\")\n",
    "print(coeff_df)\n",
    "print(f\"Intercept: {lr_model.intercept_:.2f}\")\n",
    "\n",
    "# Predict on test data and evaluate performance\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_mse = mean_squared_error(y_test, y_pred_lr)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_mape = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"MAE:  {lr_mae:.2f}\")\n",
    "print(f\"MSE:  {lr_mse:.2f}\")\n",
    "print(f\"RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"MAPE: {lr_mape:.4f} ({lr_mape*100:.2f}%)\")\n",
    "\n",
    "# ===============================\n",
    "# Step 3: SGD Regressor Model\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\\nSGD REGRESSOR\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Standardize features (required for gradient-based models like SGD)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train SGD Regressor\n",
    "sgd_model = SGDRegressor(max_iter=1000, random_state=42)\n",
    "sgd_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display learned coefficients (note: scaled features)\n",
    "sgd_coeff_df = pd.DataFrame(sgd_model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(\"Coefficients (scaled features):\")\n",
    "print(sgd_coeff_df)\n",
    "print(f\"Intercept: {sgd_model.intercept_[0]:.2f}\")\n",
    "\n",
    "# Predict and evaluate performance\n",
    "y_pred_sgd = sgd_model.predict(X_test_scaled)\n",
    "sgd_mae = mean_absolute_error(y_test, y_pred_sgd)\n",
    "sgd_mse = mean_squared_error(y_test, y_pred_sgd)\n",
    "sgd_rmse = np.sqrt(sgd_mse)\n",
    "sgd_mape = mean_absolute_percentage_error(y_test, y_pred_sgd)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"MAE:  {sgd_mae:.2f}\")\n",
    "print(f\"MSE:  {sgd_mse:.2f}\")\n",
    "print(f\"RMSE: {sgd_rmse:.2f}\")\n",
    "print(f\"MAPE: {sgd_mape:.4f} ({sgd_mape*100:.2f}%)\")\n",
    "\n",
    "# ===============================\n",
    "# Step 4: Model Comparison\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\\nMODEL COMPARISON\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a comparison table of evaluation metrics\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'MSE', 'RMSE', 'MAPE'],\n",
    "    'LinearRegression': [lr_mae, lr_mse, lr_rmse, lr_mape],\n",
    "    'SGDRegressor': [sgd_mae, sgd_mse, sgd_rmse, sgd_mape]\n",
    "})\n",
    "print(comparison.round(4))\n",
    "\n",
    "# ===============================\n",
    "# Step 5: Metrics Explanation\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n\\nMETRICS TRADE-OFFS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"MAE  - Average absolute error, robust to outliers.\")\n",
    "print(\"MSE  - Penalizes large errors more due to squaring.\")\n",
    "print(\"RMSE - Same units as target; balances MAE and MSE.\")\n",
    "print(\"MAPE - Scale-independent; expresses error in %.\")\n",
    "\n",
    "print(f\"\\nNote: RMSE is often preferred because it:\")\n",
    "print(\"- Uses the same unit as the target variable\")\n",
    "print(\"- Penalizes larger errors more than MAE\")\n",
    "print(\"- Is more interpretable than MSE in most cases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731ab48",
   "metadata": {},
   "source": [
    "### QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7250a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "KNN: 0.5556\n",
      "Logistic Regression: 0.5920\n",
      "SGD: 0.5755\n",
      "\n",
      "Best Model: Logistic Regression (0.5920)\n",
      "Model saved as best_cat_dog_model.pkl\n",
      "\n",
      "Test Results:\n",
      "Cat (1).jpg: Cat (83.2%) (Actual: Cat)\n",
      "Dog (1).jpg: Dog (77.8%) (Actual: Dog)\n",
      "\n",
      "To test internet images: test_image('path_to_image.jpg')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Path to the dataset directory\n",
    "base_path = r\"C:\\Users\\rtape\\Downloads\\Seneca\\CVI620NSB_Summer2025\\codes\\Assignment2\\Q2\"\n",
    "\n",
    "# -------------------\n",
    "# Step 1: Load and preprocess data\n",
    "# -------------------\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all image files in the dataset\n",
    "for address in glob.glob(os.path.join(base_path, '*', '*', '*')):\n",
    "    img = cv2.imread(address)  # Read image\n",
    "    if img is None:\n",
    "        continue  # Skip if image couldn't be loaded\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32))  # Resize to 32x32 pixels\n",
    "    img = img.flatten() / 255.0      # Flatten to 1D array and normalize pixel values\n",
    "    data.append(img)\n",
    "    \n",
    "    # Assign label based on folder name: 0 = Cat, 1 = Dog\n",
    "    labels.append(0 if 'Cat' in address else 1)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(data)\n",
    "y = np.array(labels)\n",
    "\n",
    "# -------------------\n",
    "# Step 2: Split and scale data\n",
    "# -------------------\n",
    "\n",
    "# Split dataset into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features to have 0 mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -------------------\n",
    "# Step 3: Train models using GridSearchCV\n",
    "# -------------------\n",
    "\n",
    "models = {}\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {'n_neighbors': [1, 3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=3)\n",
    "knn_grid.fit(X_train_scaled, y_train)\n",
    "models['KNN'] = (knn_grid.best_estimator_, accuracy_score(y_test, knn_grid.predict(X_test_scaled)))\n",
    "\n",
    "# Logistic Regression\n",
    "lr_params = {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
    "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), lr_params, cv=3)\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "models['Logistic Regression'] = (lr_grid.best_estimator_, accuracy_score(y_test, lr_grid.predict(X_test_scaled)))\n",
    "\n",
    "# SGD Classifier (Stochastic Gradient Descent)\n",
    "sgd_params = {'alpha': [0.0001, 0.001, 0.01], 'loss': ['hinge', 'log_loss']}\n",
    "sgd_grid = GridSearchCV(SGDClassifier(max_iter=1000), sgd_params, cv=3)\n",
    "sgd_grid.fit(X_train_scaled, y_train)\n",
    "models['SGD'] = (sgd_grid.best_estimator_, accuracy_score(y_test, sgd_grid.predict(X_test_scaled)))\n",
    "\n",
    "# -------------------\n",
    "# Step 4: Compare model performances\n",
    "# -------------------\n",
    "\n",
    "print(\"RESULTS:\")\n",
    "for name, (model, acc) in models.items():\n",
    "    print(f\"{name}: {acc:.4f}\")  # Print accuracy of each model\n",
    "\n",
    "# -------------------\n",
    "# Step 5: Save the best model\n",
    "# -------------------\n",
    "\n",
    "# Identify the best performing model\n",
    "best_name = max(models.keys(), key=lambda x: models[x][1])\n",
    "best_model, best_acc = models[best_name]\n",
    "\n",
    "# Save best model and scaler to disk\n",
    "joblib.dump(best_model, 'best_cat_dog_model.pkl')\n",
    "joblib.dump(scaler, 'best_cat_dog_scaler.pkl')\n",
    "\n",
    "print(f\"\\nBest Model: {best_name} ({best_acc:.4f})\")\n",
    "print(\"Model saved as best_cat_dog_model.pkl\")\n",
    "\n",
    "# -------------------\n",
    "# Step 6: Test new image function\n",
    "# -------------------\n",
    "\n",
    "# Predict label for new image\n",
    "def test_image(image_path):\n",
    "    # Load saved model and scaler\n",
    "    model = joblib.load('best_cat_dog_model.pkl')\n",
    "    scaler = joblib.load('best_cat_dog_scaler.pkl')\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return \"Could not load image\"\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img.flatten() / 255.0\n",
    "    img_scaled = scaler.transform(img.reshape(1, -1))\n",
    "    \n",
    "    # Predict label (0 = Cat, 1 = Dog)\n",
    "    prediction = model.predict(img_scaled)[0]\n",
    "    label = \"Cat\" if prediction == 0 else \"Dog\"\n",
    "    \n",
    "    # If model supports confidence scoring\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        confidence = max(model.predict_proba(img_scaled)[0]) * 100\n",
    "        return f\"{label} ({confidence:.1f}%)\"\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "# -------------------\n",
    "# Step 7: Test on sample dataset images\n",
    "# -------------------\n",
    "\n",
    "# List of test images to try\n",
    "test_paths = [\n",
    "    os.path.join(base_path, \"test\", \"Cat\", \"Cat (1).jpg\"),\n",
    "    os.path.join(base_path, \"test\", \"Dog\", \"Dog (1).jpg\")\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for path in test_paths:\n",
    "    if os.path.exists(path):\n",
    "        result = test_image(path)\n",
    "        actual = \"Cat\" if \"Cat\" in path else \"Dog\"\n",
    "        print(f\"{os.path.basename(path)}: {result} (Actual: {actual})\")\n",
    "\n",
    "# -------------------\n",
    "# Final Note\n",
    "# -------------------\n",
    "\n",
    "print(\"\\nTo test internet images: test_image('path_to_image.jpg')\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python CVI620NSB",
   "language": "python",
   "name": "cvi620nsb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
